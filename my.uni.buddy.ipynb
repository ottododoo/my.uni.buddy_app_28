{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbec7d6b-ce48-4022-afa9-7266fb22f681",
   "metadata": {},
   "source": [
    "# 1.  Installations and Settings üõ†Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "100f090c-8ea8-4c41-b819-c4a5b26a6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -qqq -U langchain-huggingface\n",
    "pip install -qqq -U langchain\n",
    "pip install -qqq -U langchain-community\n",
    "pip install -qqq -U faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a4a9e9-6cb0-402c-a105-f8da51a14da5",
   "metadata": {},
   "source": [
    "# 2.  Setting up your LLM üß†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04641bee-2299-421a-be46-d3df35d696ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# This info's at the top of each HuggingFace model page\n",
    "hf_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id = hf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a0bed-8dd2-4cda-81d7-5e211883c9a3",
   "metadata": {},
   "source": [
    "# 3.  Retrieval Augmented Generation üîÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb4b90b-2c33-4677-b904-eb110711d2bf",
   "metadata": {},
   "source": [
    "## 3.1 loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a14fe8-6887-45a5-a870-52bc82c5afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "AsyncChromiumLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5907e1-b9d8-4512-88eb-03bb35ecb3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# load dependancies\n",
    "from langchain_community.document_loaders import AsyncHtmlLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2522f6c0-ebb6-4e23-9886-7727c052f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.daad.de/en/studying-in-germany/scholarships/daad-scholarships/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/universities/the-right-degree-programme/\", \n",
    "    \"https://www2.daad.de/deutschland/stipendium/datenbank/en/21148-scholarship-database/\", \n",
    "    \"https://www2.daad.de/deutschland/stipendium/datenbank/en/21148-scholarship-database/?status=&origin=&subjectGrps=&daad=&intention=&q=&page=1&detail=57742130\",\n",
    "    \"https://www2.daad.de/deutschland/stipendium/datenbank/en/21148-scholarship-database/?status=&origin=&subjectGrps=&daad=&intention=&q=&page=1&detail=57135739\",\n",
    "    \"https://www2.daad.de/deutschland/stipendium/datenbank/en/21148-scholarship-database/?status=&origin=&subjectGrps=&daad=&intention=&q=&page=1&detail=57507783\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/universities/universities/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/universities/haw/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/universities/dual-studies/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/scholarships/daad-scholarships/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/scholarships/information-for-scholarship-applicants/#requirements\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/scholarships/funding-options/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/requirements/\", \n",
    "    \"https://www.daad.de/en/studying-in-germany/requirements/overview/\", \n",
    "    \"https://www.daad.de/en/studying-in-germany/requirements/application-process/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/requirements/enrolling/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/requirements/studienkollegs/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/living-in-germany/visa/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/living-in-germany/registering/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/living-in-germany/health-insurance/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/living-in-germany/renting/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/living-in-germany/german-language/learning/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/living-in-germany/german-language/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/living-in-germany/finances/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/living-in-germany/safety/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/work-career/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/work-career/career-planning/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/work-career/side-jobs/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/work-career/work-placements/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/advisory-service/publications/\",\n",
    "    \"https://www.daad.de/en/studying-in-germany/advisory-service/psychological-wellbeing/\",\n",
    "    \"https://www.daad.de/en/the-daad/mobility-with-a-disability/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1dd279e-50d8-4974-94a1-d56487a2dd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 32/32 [00:10<00:00,  3.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "\n",
    "loader = AsyncHtmlLoader(urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0571a83b-2920-464f-9841-752797531fcf",
   "metadata": {},
   "source": [
    "## 3.2 Splitting the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48d4cc79-280d-4cba-b4cd-d938749bf0a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800,\n",
    "                                               chunk_overlap=150)\n",
    "\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59582d90-a0dd-480e-9c7b-f1b2d8d6643e",
   "metadata": {},
   "source": [
    "## 3.3 Creating vectors with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f93692c-a044-473a-8718-44d430190378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ottododoo/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "embeddings_folder = \"docs\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model,\n",
    "                                   cache_folder=embeddings_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043397c-31c5-49f5-9362-75fb04fe0075",
   "metadata": {},
   "source": [
    "## 3.4 Creating a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c4c10ba-e6a8-4a4a-b155-3f0fda7e5cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vector_db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0b9f02-1798-455d-9406-a379e8681931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_db.save_local(\"docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab5d4d57-e69f-4c3e-a6f3-92e79657fdf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 3}), # top 2 results only, speed things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "102d289d-bb6c-4bbb-8a92-2f9cf5bd0ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = 'chat_history',\n",
    "                                  return_messages = True,\n",
    "                                  output_key = 'answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1cb000c-2fbb-42ed-919d-c624743d238d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ottododoo/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "hf_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(repo_id=hf_model)\n",
    "\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "embeddings_folder = \"docs\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model,\n",
    "                                   cache_folder=embeddings_folder)\n",
    "\n",
    "vector_db = FAISS.load_local(\"docs\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = 'chat_history',\n",
    "                                  return_messages = True,\n",
    "                                  output_key = 'answer')  # Set output_key to 'answer'\n",
    "\n",
    "template = \"\"\"You are a nice chatbot having a conversation with a human. Answer the question based only on the following context and previous conversation. Keep your answers short and succinct.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "Context to answer question:\n",
    "{context}\n",
    "\n",
    "New human question: {question}\n",
    "Response:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template = template,\n",
    "                        input_variables = [\"context\", \"question\"])\n",
    "\n",
    "# chain\n",
    "chain = ConversationalRetrievalChain.from_llm(llm,\n",
    "                                              retriever = retriever,\n",
    "                                              memory = memory,\n",
    "                                              return_source_documents = True,\n",
    "                                              combine_docs_chain_kwargs = {\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddfffff9-84c8-4496-bab4-c15b9cae75e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streamlit==1.35.0\n",
      "langchain_community==0.2.6\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if hasattr(m, '__version__')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1b9a1ce-a07f-4c6c-93d5-ac2127c777bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streamlit==1.35.0\n",
      "langchain_community==0.2.6\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Print versions of the imported modules\n",
    "import streamlit as st\n",
    "\n",
    "print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if hasattr(m, '__version__')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
